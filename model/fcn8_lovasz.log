Model Architecture to be Trained: 
FCN8(
  (pool3): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (pool4): Sequential(
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (pool5): Sequential(
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (upconv4): Sequential(
    (0): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout2d(p=0.5, inplace=False)
  )
  (upconv3): Sequential(
    (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout2d(p=0.5, inplace=False)
  )
  (upconv): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout2d(p=0.5, inplace=False)
    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (4): LeakyReLU(negative_slope=0.01)
    (5): Dropout2d(p=0.5, inplace=False)
    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (7): LeakyReLU(negative_slope=0.01)
    (8): Dropout2d(p=0.5, inplace=False)
    (9): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))
  )
)
~~~~~~~~~~~~~~~
loading ./voc2012_train.h5
loading ./voc2012_val.h5
~~~~~~~~~~~~~~~
here
lovasz
criterion: LovaszSoftmaxLoss
in LovaszSoftmax loss
Started training model...
/content/criterion/DiceCrossEntropy.py:131: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  vprobas = probas[valid.nonzero().squeeze()]
Epoch:1, Loss:0.8469 Val set: Average loss: 0.0148, Accuracy: 35326/50176 (70%)
Epoch:2, Loss:0.8146 Val set: Average loss: 0.0147, Accuracy: 32275/50176 (64%)
Epoch:3, Loss:0.8332 Val set: Average loss: 0.0146, Accuracy: 18846/50176 (38%)
Epoch:4, Loss:0.7956 Val set: Average loss: 0.0145, Accuracy: 28469/50176 (57%)
Epoch:5, Loss:0.8011 Val set: Average loss: 0.0145, Accuracy: 25808/50176 (51%)
Epoch:6, Loss:0.8002 Val set: Average loss: 0.0145, Accuracy: 25820/50176 (51%)
Epoch:7, Loss:0.7961 Val set: Average loss: 0.0145, Accuracy: 22440/50176 (45%)
Epoch:8, Loss:0.7974 Val set: Average loss: 0.0144, Accuracy: 26966/50176 (54%)
Epoch:9, Loss:0.7895 Val set: Average loss: 0.0145, Accuracy: 25975/50176 (52%)
Epoch:10, Loss:0.7636 Val set: Average loss: 0.0145, Accuracy: 29178/50176 (58%)
Epoch:11, Loss:0.7845 Val set: Average loss: 0.0144, Accuracy: 25788/50176 (51%)
Epoch:12, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:13, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:14, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:15, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:16, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:17, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:18, Loss:0.8189 Val set: Average loss: 0.0151, Accuracy: 36725/50176 (73%)
Epoch:19, Loss:0.8095 Val set: Average loss: 0.0144, Accuracy: 23948/50176 (48%)
Epoch:20, Loss:0.8198 Val set: Average loss: 0.0143, Accuracy: 24335/50176 (48%)
Epoch:21, Loss:0.8076 Val set: Average loss: 0.0142, Accuracy: 23660/50176 (47%)
Epoch:22, Loss:0.7728 Val set: Average loss: 0.0143, Accuracy: 30189/50176 (60%)
Epoch:23, Loss:0.7893 Val set: Average loss: 0.0140, Accuracy: 22195/50176 (44%)
Epoch:24, Loss:0.7557 Val set: Average loss: 0.0139, Accuracy: 26836/50176 (53%)
Epoch:25, Loss:0.7662 Val set: Average loss: 0.0138, Accuracy: 26198/50176 (52%)
Epoch:26, Loss:0.7698 Val set: Average loss: 0.0141, Accuracy: 28151/50176 (56%)
Epoch:27, Loss:0.7233 Val set: Average loss: 0.0138, Accuracy: 25662/50176 (51%)
Epoch:28, Loss:0.7174 Val set: Average loss: 0.0137, Accuracy: 26999/50176 (54%)
Epoch:29, Loss:0.7431 Val set: Average loss: 0.0143, Accuracy: 22042/50176 (44%)
Epoch:30, Loss:0.7162 Val set: Average loss: 0.0137, Accuracy: 23463/50176 (47%)
Epoch:31, Loss:0.7198 Val set: Average loss: 0.0136, Accuracy: 17424/50176 (35%)
Epoch:32, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:33, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:34, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:35, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:36, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:37, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:38, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:39, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 25401/50176 (51%)
Epoch:40, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 27838/50176 (55%)
Epoch:41, Loss:0.7956 Val set: Average loss: 0.0145, Accuracy: 28469/50176 (57%)
Epoch:42, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:43, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:44, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:45, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:46, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:47, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:48, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:49, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 25401/50176 (51%)
Epoch:50, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 27838/50176 (55%)
Epoch:51, Loss:0.7198 Val set: Average loss: 0.0136, Accuracy: 17424/50176 (35%)
Epoch:52, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:53, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:54, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:55, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:56, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:57, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:58, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:59, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 27838/50176 (55%)
Epoch:60, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 28469/50176 (57%)
Epoch:61, Loss:0.7198 Val set: Average loss: 0.0136, Accuracy: 17424/50176 (35%)
Epoch:62, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:63, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:64, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:65, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:66, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:67, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:68, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:69, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 27838/50176 (55%)
Epoch:70, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 28469/50176 (57%)
Epoch:71, Loss:0.7198 Val set: Average loss: 0.0136, Accuracy: 17424/50176 (35%)
Epoch:72, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:73, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:74, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:75, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:76, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:77, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:78, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:79, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 27838/50176 (55%)
Epoch:80, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 28469/50176 (57%)
Epoch:81, Loss:0.7198 Val set: Average loss: 0.0136, Accuracy: 17424/50176 (35%)
Epoch:82, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:83, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:84, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:85, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:86, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:87, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:88, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:89, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 27838/50176 (55%)
Epoch:90, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 28469/50176 (57%)
Epoch:91, Loss:0.7198 Val set: Average loss: 0.0136, Accuracy: 17424/50176 (35%)
Epoch:92, Loss:0.6888 Val set: Average loss: 0.0136, Accuracy: 20049/50176 (40%)
Epoch:93, Loss:0.6613 Val set: Average loss: 0.0139, Accuracy: 25504/50176 (51%)
Epoch:94, Loss:0.6187 Val set: Average loss: 0.0134, Accuracy: 25208/50176 (50%)
Epoch:95, Loss:0.6080 Val set: Average loss: 0.0135, Accuracy: 22024/50176 (44%)
Epoch:96, Loss:0.6597 Val set: Average loss: 0.0134, Accuracy: 23965/50176 (48%)
Epoch:97, Loss:0.6290 Val set: Average loss: 0.0135, Accuracy: 26178/50176 (52%)
Epoch:98, Loss:0.5975 Val set: Average loss: 0.0134, Accuracy: 26835/50176 (53%)
Epoch:99, Loss:0.6105 Val set: Average loss: 0.0136, Accuracy: 27838/50176 (55%)
Epoch:100, Loss:0.6726 Val set: Average loss: 0.0134, Accuracy: 28469/50176 (57%)
Training time:  446348:46:41.21