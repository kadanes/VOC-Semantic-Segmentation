FCN_resnet_bn(
  (pool4): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (upconv4): Sequential(
    (0): ReLU()
    (1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (upconv): Sequential(
    (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))
  )
)
Criterion: DiceLoss(
  (CE_loss): CrossEntropyLoss()
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 1e-05
)
Learning Rate: 0.0001
Weight Decay: 1e-05
Batch Size: 10
Epochs: 100
-----------------------
Epoch:1, Loss:1.7290 Val set: Average loss: 0.0264, Accuracy: 33581/50176 (67%)
Epoch:2, Loss:0.6324 Val set: Average loss: 0.0109, Accuracy: 38745/50176 (77%)
Epoch:3, Loss:0.2252 Val set: Average loss: 0.0105, Accuracy: 38879/50176 (77%)
Epoch:4, Loss:0.2505 Val set: Average loss: 0.0105, Accuracy: 38767/50176 (77%)
Epoch:5, Loss:0.1395 Val set: Average loss: 0.0102, Accuracy: 38932/50176 (78%)
Epoch:6, Loss:0.1362 Val set: Average loss: 0.0112, Accuracy: 38544/50176 (77%)
Epoch:7, Loss:0.1179 Val set: Average loss: 0.0079, Accuracy: 40334/50176 (80%)
Epoch:8, Loss:0.0966 Val set: Average loss: 0.0075, Accuracy: 40441/50176 (81%)
Epoch:9, Loss:0.0932 Val set: Average loss: 0.0074, Accuracy: 40912/50176 (82%)
Epoch:10, Loss:0.0659 Val set: Average loss: 0.0079, Accuracy: 40833/50176 (81%)
Epoch:11, Loss:0.0629 Val set: Average loss: 0.0078, Accuracy: 40616/50176 (81%)
Epoch:12, Loss:0.1218 Val set: Average loss: 0.0093, Accuracy: 38455/50176 (77%)
Epoch:13, Loss:0.1389 Val set: Average loss: 0.0104, Accuracy: 40029/50176 (80%)
Epoch:14, Loss:0.0590 Val set: Average loss: 0.0081, Accuracy: 40376/50176 (80%)
Epoch:15, Loss:0.0827 Val set: Average loss: 0.0077, Accuracy: 41238/50176 (82%)
Epoch:16, Loss:0.0950 Val set: Average loss: 0.0078, Accuracy: 40288/50176 (80%)
Epoch:17, Loss:0.0729 Val set: Average loss: 0.0078, Accuracy: 40951/50176 (82%)
Epoch:18, Loss:0.0510 Val set: Average loss: 0.0073, Accuracy: 41257/50176 (82%)
Epoch:19, Loss:0.0438 Val set: Average loss: 0.0084, Accuracy: 40736/50176 (81%)
Epoch:20, Loss:0.0350 Val set: Average loss: 0.0080, Accuracy: 41272/50176 (82%)
Epoch:21, Loss:0.0339 Val set: Average loss: 0.0070, Accuracy: 41479/50176 (83%)
Epoch:22, Loss:0.0312 Val set: Average loss: 0.0078, Accuracy: 41172/50176 (82%)
Epoch:23, Loss:0.0329 Val set: Average loss: 0.0067, Accuracy: 41379/50176 (82%)
Epoch:24, Loss:0.0768 Val set: Average loss: 0.0073, Accuracy: 41332/50176 (82%)
Epoch:25, Loss:0.0573 Val set: Average loss: 0.0078, Accuracy: 40213/50176 (80%)
Epoch:26, Loss:0.0320 Val set: Average loss: 0.0068, Accuracy: 41006/50176 (82%)
Epoch:27, Loss:0.0495 Val set: Average loss: 0.0081, Accuracy: 41289/50176 (82%)
Epoch:28, Loss:0.0282 Val set: Average loss: 0.0089, Accuracy: 41542/50176 (83%)
Epoch:29, Loss:0.0286 Val set: Average loss: 0.0084, Accuracy: 41240/50176 (82%)
Epoch:30, Loss:0.0394 Val set: Average loss: 0.0081, Accuracy: 41526/50176 (83%)
Epoch:31, Loss:0.0692 Val set: Average loss: 0.0073, Accuracy: 41153/50176 (82%)
Epoch:32, Loss:0.0654 Val set: Average loss: 0.0075, Accuracy: 40535/50176 (81%)
Epoch:33, Loss:0.0332 Val set: Average loss: 0.0077, Accuracy: 40801/50176 (81%)
Epoch:34, Loss:0.0290 Val set: Average loss: 0.0081, Accuracy: 40856/50176 (81%)
Epoch:35, Loss:0.0361 Val set: Average loss: 0.0090, Accuracy: 40482/50176 (81%)
Epoch:36, Loss:0.0214 Val set: Average loss: 0.0081, Accuracy: 40690/50176 (81%)
Epoch:37, Loss:0.0322 Val set: Average loss: 0.0084, Accuracy: 39984/50176 (80%)
Epoch:38, Loss:0.0437 Val set: Average loss: 0.0079, Accuracy: 41005/50176 (82%)
Epoch:39, Loss:0.0316 Val set: Average loss: 0.0092, Accuracy: 41041/50176 (82%)
Epoch:40, Loss:0.0267 Val set: Average loss: 0.0092, Accuracy: 41374/50176 (82%)
Epoch:41, Loss:0.0338 Val set: Average loss: 0.0115, Accuracy: 39829/50176 (79%)
Epoch:42, Loss:0.0809 Val set: Average loss: 0.0120, Accuracy: 39916/50176 (80%)
Epoch:43, Loss:0.0337 Val set: Average loss: 0.0130, Accuracy: 39225/50176 (78%)
Epoch:44, Loss:0.0317 Val set: Average loss: 0.0098, Accuracy: 40348/50176 (80%)
Epoch:45, Loss:0.0328 Val set: Average loss: 0.0106, Accuracy: 39292/50176 (78%)
Epoch:46, Loss:0.0415 Val set: Average loss: 0.0076, Accuracy: 40635/50176 (81%)
Epoch:47, Loss:0.0311 Val set: Average loss: 0.0076, Accuracy: 41197/50176 (82%)
Epoch:48, Loss:0.0286 Val set: Average loss: 0.0087, Accuracy: 41440/50176 (83%)
Epoch:49, Loss:0.0282 Val set: Average loss: 0.0086, Accuracy: 41571/50176 (83%)
Epoch:50, Loss:0.0306 Val set: Average loss: 0.0086, Accuracy: 41252/50176 (82%)
Epoch:51, Loss:0.0212 Val set: Average loss: 0.0091, Accuracy: 41400/50176 (83%)
Epoch:52, Loss:0.0346 Val set: Average loss: 0.0093, Accuracy: 40179/50176 (80%)
Epoch:53, Loss:0.0328 Val set: Average loss: 0.0088, Accuracy: 40050/50176 (80%)
Epoch:54, Loss:0.0256 Val set: Average loss: 0.0098, Accuracy: 39903/50176 (80%)
Epoch:55, Loss:0.0390 Val set: Average loss: 0.0087, Accuracy: 41225/50176 (82%)
Epoch:56, Loss:0.0157 Val set: Average loss: 0.0091, Accuracy: 41175/50176 (82%)
Epoch:57, Loss:0.0375 Val set: Average loss: 0.0106, Accuracy: 40640/50176 (81%)
Epoch:58, Loss:0.0342 Val set: Average loss: 0.0120, Accuracy: 40412/50176 (81%)
Epoch:59, Loss:0.0204 Val set: Average loss: 0.0120, Accuracy: 40534/50176 (81%)
Epoch:60, Loss:0.0158 Val set: Average loss: 0.0105, Accuracy: 41050/50176 (82%)
Epoch:61, Loss:0.0156 Val set: Average loss: 0.0110, Accuracy: 40916/50176 (82%)
Epoch:62, Loss:0.0170 Val set: Average loss: 0.0113, Accuracy: 40941/50176 (82%)
Epoch:63, Loss:0.0190 Val set: Average loss: 0.0094, Accuracy: 40953/50176 (82%)
Epoch:64, Loss:0.0199 Val set: Average loss: 0.0104, Accuracy: 41104/50176 (82%)
Epoch:65, Loss:0.0335 Val set: Average loss: 0.0089, Accuracy: 40542/50176 (81%)
Epoch:66, Loss:0.0205 Val set: Average loss: 0.0091, Accuracy: 40261/50176 (80%)
Epoch:67, Loss:0.0157 Val set: Average loss: 0.0086, Accuracy: 40625/50176 (81%)
Epoch:68, Loss:0.0146 Val set: Average loss: 0.0095, Accuracy: 41012/50176 (82%)
Epoch:69, Loss:0.0153 Val set: Average loss: 0.0095, Accuracy: 40943/50176 (82%)
Epoch:70, Loss:0.0175 Val set: Average loss: 0.0107, Accuracy: 41062/50176 (82%)
Epoch:71, Loss:0.0202 Val set: Average loss: 0.0103, Accuracy: 41046/50176 (82%)
Epoch:72, Loss:0.0250 Val set: Average loss: 0.0083, Accuracy: 41263/50176 (82%)
Epoch:73, Loss:0.0203 Val set: Average loss: 0.0100, Accuracy: 39817/50176 (79%)
Epoch:74, Loss:0.0268 Val set: Average loss: 0.0098, Accuracy: 40887/50176 (81%)
Epoch:75, Loss:0.0154 Val set: Average loss: 0.0095, Accuracy: 40858/50176 (81%)
Epoch:76, Loss:0.0169 Val set: Average loss: 0.0102, Accuracy: 40473/50176 (81%)
Epoch:77, Loss:0.0228 Val set: Average loss: 0.0098, Accuracy: 40580/50176 (81%)
Epoch:78, Loss:0.0152 Val set: Average loss: 0.0090, Accuracy: 41231/50176 (82%)
Epoch:79, Loss:0.0163 Val set: Average loss: 0.0090, Accuracy: 41226/50176 (82%)
Epoch:80, Loss:0.0114 Val set: Average loss: 0.0084, Accuracy: 41466/50176 (83%)
Epoch:81, Loss:0.0141 Val set: Average loss: 0.0104, Accuracy: 41225/50176 (82%)
Epoch:82, Loss:0.0279 Val set: Average loss: 0.0117, Accuracy: 40146/50176 (80%)
Epoch:83, Loss:0.0130 Val set: Average loss: 0.0126, Accuracy: 39945/50176 (80%)
Epoch:84, Loss:0.0157 Val set: Average loss: 0.0104, Accuracy: 41151/50176 (82%)
Epoch:85, Loss:0.0119 Val set: Average loss: 0.0096, Accuracy: 41513/50176 (83%)
Epoch:86, Loss:0.0273 Val set: Average loss: 0.0093, Accuracy: 41201/50176 (82%)
Epoch:87, Loss:0.0199 Val set: Average loss: 0.0102, Accuracy: 41100/50176 (82%)
Epoch:88, Loss:0.0127 Val set: Average loss: 0.0100, Accuracy: 41367/50176 (82%)
Epoch:89, Loss:0.0186 Val set: Average loss: 0.0102, Accuracy: 40717/50176 (81%)
Epoch:90, Loss:0.0132 Val set: Average loss: 0.0095, Accuracy: 40798/50176 (81%)
Epoch:91, Loss:0.0232 Val set: Average loss: 0.0099, Accuracy: 40776/50176 (81%)
Epoch:92, Loss:0.0135 Val set: Average loss: 0.0120, Accuracy: 40309/50176 (80%)
Epoch:93, Loss:0.0135 Val set: Average loss: 0.0104, Accuracy: 40498/50176 (81%)
Epoch:94, Loss:0.0288 Val set: Average loss: 0.0111, Accuracy: 40106/50176 (80%)
Epoch:95, Loss:0.0132 Val set: Average loss: 0.0091, Accuracy: 41036/50176 (82%)
Epoch:96, Loss:0.0139 Val set: Average loss: 0.0084, Accuracy: 41415/50176 (83%)
Epoch:97, Loss:0.0096 Val set: Average loss: 0.0086, Accuracy: 41276/50176 (82%)
Epoch:98, Loss:0.0123 Val set: Average loss: 0.0092, Accuracy: 40798/50176 (81%)
Epoch:99, Loss:0.0198 Val set: Average loss: 0.0089, Accuracy: 39945/50176 (80%)
Epoch:100, Loss:0.0105 Val set: Average loss: 0.0096, Accuracy: 39945/50176 (80%)
Training time: 446351:26:00.54