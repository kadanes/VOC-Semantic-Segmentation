Skip(
  (down1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout2d(p=0.5, inplace=False)
  )
  (down2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout2d(p=0.5, inplace=False)
  )
  (down3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout2d(p=0.5, inplace=False)
  )
  (down4): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout2d(p=0.5, inplace=False)
  )
  (up4): Sequential(
    (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout2d(p=0.5, inplace=False)
  )
  (up3): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout2d(p=0.5, inplace=False)
  )
  (up2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout2d(p=0.5, inplace=False)
  )
  (up1): Sequential(
    (0): ConvTranspose2d(64, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  )
)
Criterion: CrossEntropyLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
Learning Rate: 0.001
Weight Decay: 1e-05
Batch Size: 128
Epochs: 200
-----------------------
Epoch:1, Loss:1.8392 
Epoch:2, Loss:1.6418 
Epoch:3, Loss:1.5465 
Epoch:4, Loss:1.5116 
Epoch:5, Loss:1.4790 
Epoch:6, Loss:1.4660 
Epoch:7, Loss:1.4567 
Epoch:8, Loss:1.3635 
Epoch:9, Loss:1.3833 
Epoch:10, Loss:1.3665 Val set: Average loss: 0.0201, Accuracy: 0/256 (0%)
Epoch:11, Loss:1.2672 
Epoch:12, Loss:1.2420 
Epoch:13, Loss:1.2000 
Epoch:14, Loss:1.1988 
Epoch:15, Loss:1.1708 
Epoch:16, Loss:1.1634 
Epoch:17, Loss:1.1725 
Epoch:18, Loss:1.1607 
Epoch:19, Loss:1.1314 
Epoch:20, Loss:1.1122 Val set: Average loss: 0.0178, Accuracy: 0/256 (0%)
Epoch:21, Loss:1.1118 
Epoch:22, Loss:1.1040 
Epoch:23, Loss:1.0958 
Epoch:24, Loss:1.0849 
Epoch:25, Loss:1.0731 
Epoch:26, Loss:1.0725 
Epoch:27, Loss:1.0476 
Epoch:28, Loss:1.0485 
Epoch:29, Loss:1.0359 
Epoch:30, Loss:1.0310 Val set: Average loss: 0.0175, Accuracy: 0/256 (0%)
Epoch:31, Loss:1.0402 
Epoch:32, Loss:1.0523 
Epoch:33, Loss:1.0211 
Epoch:34, Loss:1.0179 
Epoch:35, Loss:1.0100 
Epoch:36, Loss:0.9921 
Epoch:37, Loss:0.9904 
Epoch:38, Loss:0.9871 
Epoch:39, Loss:0.9768 
Epoch:40, Loss:0.9904 Val set: Average loss: 0.0168, Accuracy: 0/256 (0%)
Epoch:41, Loss:0.9858 
Epoch:42, Loss:0.9574 
Epoch:43, Loss:0.9483 
Epoch:44, Loss:0.9260 
Epoch:45, Loss:0.9321 
Epoch:46, Loss:0.9274 
Epoch:47, Loss:0.9226 
Epoch:48, Loss:0.9433 
Epoch:49, Loss:0.9344 
Epoch:50, Loss:0.9080 Val set: Average loss: 0.0167, Accuracy: 0/256 (0%)
Epoch:51, Loss:0.9163 
Epoch:52, Loss:0.9037 
Epoch:53, Loss:0.8769 
Epoch:54, Loss:0.8688 
Epoch:55, Loss:0.8695 
Epoch:56, Loss:0.8564 
Epoch:57, Loss:0.8291 
Epoch:58, Loss:0.8309 
Epoch:59, Loss:0.8095 
Epoch:60, Loss:0.7984 Val set: Average loss: 0.0168, Accuracy: 0/256 (0%)
Epoch:61, Loss:0.7778 
Epoch:62, Loss:0.7601 
Epoch:63, Loss:0.7581 
Epoch:64, Loss:0.7561 
Epoch:65, Loss:0.7565 
Epoch:66, Loss:0.7512 
Epoch:67, Loss:0.7044 
Epoch:68, Loss:0.6862 
Epoch:69, Loss:0.7112 
Epoch:70, Loss:0.7151 Val set: Average loss: 0.0178, Accuracy: 0/256 (0%)
Epoch:71, Loss:0.6654 
Epoch:72, Loss:0.6766 
Epoch:73, Loss:0.6808 
Epoch:74, Loss:0.6512 
Epoch:75, Loss:0.6504 
Epoch:76, Loss:0.6783 
Epoch:77, Loss:0.6611 
Epoch:78, Loss:0.6382 
Epoch:79, Loss:0.6106 
Epoch:80, Loss:0.6197 Val set: Average loss: 0.0186, Accuracy: 0/256 (0%)
Epoch:81, Loss:0.5738 
Epoch:82, Loss:0.5373 
Epoch:83, Loss:0.5224 
Epoch:84, Loss:0.5330 
Epoch:85, Loss:0.4980 
Epoch:86, Loss:0.4907 
Epoch:87, Loss:0.4760 
Epoch:88, Loss:0.4438 
Epoch:89, Loss:0.4163 
Epoch:90, Loss:0.3945 Val set: Average loss: 0.0220, Accuracy: 0/256 (0%)
Epoch:91, Loss:0.4194 
Epoch:92, Loss:0.4167 
Epoch:93, Loss:0.4146 
Epoch:94, Loss:0.4148 
Epoch:95, Loss:0.3807 
Epoch:96, Loss:0.3954 
Epoch:97, Loss:0.3583 
Epoch:98, Loss:0.3633 
Epoch:99, Loss:0.3692 
Epoch:100, Loss:0.3712 Val set: Average loss: 0.0236, Accuracy: 0/256 (0%)
Epoch:101, Loss:0.3373 
Epoch:102, Loss:0.3234 
Epoch:103, Loss:0.2836 
Epoch:104, Loss:0.2973 
Epoch:105, Loss:0.2777 
Epoch:106, Loss:0.2534 
Epoch:107, Loss:0.2530 
Epoch:108, Loss:0.2569 
Epoch:109, Loss:0.2712 
Epoch:110, Loss:0.2482 Val set: Average loss: 0.0284, Accuracy: 0/256 (0%)
Epoch:111, Loss:0.2474 
Epoch:112, Loss:0.2468 
Epoch:113, Loss:0.2527 
Epoch:114, Loss:0.2683 
Epoch:115, Loss:0.2437 
Epoch:116, Loss:0.2371 
Epoch:117, Loss:0.2242 
Epoch:118, Loss:0.2320 
Epoch:119, Loss:0.2126 
Epoch:120, Loss:0.2073 Val set: Average loss: 0.0296, Accuracy: 0/256 (0%)
Epoch:121, Loss:0.2070 
Epoch:122, Loss:0.2057 
Epoch:123, Loss:0.1830 
Epoch:124, Loss:0.1615 
Epoch:125, Loss:0.1523 
Epoch:126, Loss:0.1495 
Epoch:127, Loss:0.1794 
Epoch:128, Loss:0.1603 
Epoch:129, Loss:0.1823 
Epoch:130, Loss:0.1600 Val set: Average loss: 0.0328, Accuracy: 0/256 (0%)
Epoch:131, Loss:0.1807 
Epoch:132, Loss:0.1738 
Epoch:133, Loss:0.1405 
Epoch:134, Loss:0.1370 
Epoch:135, Loss:0.1465 
Epoch:136, Loss:0.1498 
Epoch:137, Loss:0.1460 
Epoch:138, Loss:0.1442 
Epoch:139, Loss:0.1373 
Epoch:140, Loss:0.1367 Val set: Average loss: 0.0379, Accuracy: 0/256 (0%)
Epoch:141, Loss:0.1597 
Epoch:142, Loss:0.1432 
Epoch:143, Loss:0.1403 
Epoch:144, Loss:0.1565 
Epoch:145, Loss:0.1405 
Epoch:146, Loss:0.1259 
Epoch:147, Loss:0.1155 
Epoch:148, Loss:0.1218 
Epoch:149, Loss:0.1145 
Epoch:150, Loss:0.1132 Val set: Average loss: 0.0388, Accuracy: 0/256 (0%)
Epoch:151, Loss:0.1123 
Epoch:152, Loss:0.1178 
Epoch:153, Loss:0.1074 
Epoch:154, Loss:0.1227 
Epoch:155, Loss:0.1213 
Epoch:156, Loss:0.1361 
Epoch:157, Loss:0.1136 
Epoch:158, Loss:0.1089 
Epoch:159, Loss:0.1151 
Epoch:160, Loss:0.1081 Val set: Average loss: 0.0365, Accuracy: 0/256 (0%)
Epoch:161, Loss:0.1000 
Epoch:162, Loss:0.0901 
Epoch:163, Loss:0.0760 
Epoch:164, Loss:0.0788 
Epoch:165, Loss:0.0786 
Epoch:166, Loss:0.0818 
Epoch:167, Loss:0.0958 
Epoch:168, Loss:0.0964 
Epoch:169, Loss:0.0955 
Epoch:170, Loss:0.0809 Val set: Average loss: 0.0410, Accuracy: 0/256 (0%)
Epoch:171, Loss:0.0903 
Epoch:172, Loss:0.0910 
Epoch:173, Loss:0.0933 
Epoch:174, Loss:0.0755 
Epoch:175, Loss:0.0734 
Epoch:176, Loss:0.0825 
Epoch:177, Loss:0.0867 
Epoch:178, Loss:0.0770 
Epoch:179, Loss:0.0773 
Epoch:180, Loss:0.0694 Val set: Average loss: 0.0423, Accuracy: 0/256 (0%)
Epoch:181, Loss:0.0685 
Epoch:182, Loss:0.0685 
Epoch:183, Loss:0.0670 
Epoch:184, Loss:0.0682 
Epoch:185, Loss:0.0704 
Epoch:186, Loss:0.0656 
Epoch:187, Loss:0.0685 
Epoch:188, Loss:0.0676 
Epoch:189, Loss:0.0818 
Epoch:190, Loss:0.0785 Val set: Average loss: 0.0442, Accuracy: 0/256 (0%)
Epoch:191, Loss:0.0737 
Epoch:192, Loss:0.0731 
Epoch:193, Loss:0.0692 
Epoch:194, Loss:0.0716 
Epoch:195, Loss:0.0646 
Epoch:196, Loss:0.0600 
Epoch:197, Loss:0.0571 
Epoch:198, Loss:0.0688 
Epoch:199, Loss:0.0694 
Epoch:200, Loss:0.0678 Val set: Average loss: 0.0448, Accuracy: 0/256 (0%)
