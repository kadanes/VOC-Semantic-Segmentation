Model Architecture to be Trained: 
FCN_resnet_bn_skp(
  (pool3): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (pool4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (pool5): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (upconv4): Sequential(
    (0): ReLU()
    (1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (upconv3): Sequential(
    (0): ReLU()
    (1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (upconv): Sequential(
    (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))
  )
)
~~~~~~~~~~~~~~~
loading ./voc2012_train.h5
loading ./voc2012_val.h5
~~~~~~~~~~~~~~~
Epoch:1, Loss:0.8483 Val set: Average loss: 0.0130, Accuracy: 5742/50176 (11%)
Epoch:2, Loss:0.5953 Val set: Average loss: 0.0123, Accuracy: 36417/50176 (73%)
Epoch:3, Loss:0.5667 Val set: Average loss: 0.0116, Accuracy: 37101/50176 (74%)
Epoch:4, Loss:0.5204 Val set: Average loss: 0.0115, Accuracy: 37262/50176 (74%)
Epoch:5, Loss:0.4988 Val set: Average loss: 0.0116, Accuracy: 32859/50176 (65%)
Epoch:6, Loss:0.3826 Val set: Average loss: 0.0114, Accuracy: 36580/50176 (73%)
Epoch:7, Loss:0.3630 Val set: Average loss: 0.0109, Accuracy: 33600/50176 (67%)
Epoch:8, Loss:0.3580 Val set: Average loss: 0.0107, Accuracy: 36802/50176 (73%)
Epoch:9, Loss:0.3198 Val set: Average loss: 0.0107, Accuracy: 40147/50176 (80%)
Epoch:10, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:11, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:12, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:13, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:14, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:15, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:16, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:17, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:18, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:19, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:20, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:21, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:22, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:23, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:24, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:25, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:26, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:27, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:28, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:29, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:30, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:31, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:32, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:33, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:34, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:35, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:36, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:37, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:38, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:39, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:40, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:41, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:42, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:43, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:44, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:45, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:46, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:47, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:48, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:49, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:50, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:51, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:52, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:53, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:54, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:55, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:56, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:57, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:58, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:59, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:60, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:61, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:62, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:63, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:64, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:65, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:66, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:67, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:68, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:69, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:70, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:71, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:72, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:73, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:74, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:75, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:76, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:77, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:78, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:79, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:80, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:81, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:82, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:83, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:84, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:85, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:86, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:87, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:88, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:89, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 34885/50176 (70%)
Epoch:90, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 36152/50176 (72%)
Epoch:91, Loss:0.5544 Val set: Average loss: 0.0135, Accuracy: 34587/50176 (69%)
Epoch:92, Loss:0.5217 Val set: Average loss: 0.0134, Accuracy: 36207/50176 (72%)
Epoch:93, Loss:0.4481 Val set: Average loss: 0.0130, Accuracy: 34779/50176 (69%)
Epoch:94, Loss:0.4623 Val set: Average loss: 0.0129, Accuracy: 36326/50176 (72%)
Epoch:95, Loss:0.5067 Val set: Average loss: 0.0127, Accuracy: 34888/50176 (70%)
Epoch:96, Loss:0.4633 Val set: Average loss: 0.0126, Accuracy: 35862/50176 (71%)
Epoch:97, Loss:0.4467 Val set: Average loss: 0.0125, Accuracy: 34873/50176 (70%)
Epoch:98, Loss:0.4183 Val set: Average loss: 0.0125, Accuracy: 34451/50176 (69%)
Epoch:99, Loss:0.5701 Val set: Average loss: 0.0137, Accuracy: 32859/50176 (65%)
Epoch:100, Loss:0.5539 Val set: Average loss: 0.0137, Accuracy: 30759/50176 (63%)
Training time:  446335:09:21.27