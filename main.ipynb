{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voc12 import VOC2012\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from model.Naive import Naive\n",
    "from train import train, predict\n",
    "from criterion.CrossEntropy import getCrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/fast-ai-imagelocal/pascal-voc.tgz \n",
    "# !tar -xzf ./pascal-voc.tgz\n",
    "# !rm -rf ./pascal-voc/VOC2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./voc2012_train.h5\n",
      "loading ./voc2012_val.h5\n"
     ]
    }
   ],
   "source": [
    "voc2012 = VOC2012('./pascal-voc/VOC2012/')\n",
    "\n",
    "ptrain = pathlib.Path('./voc2012_train.h5')\n",
    "pval = pathlib.Path('./voc2012_val.h5')\n",
    "\n",
    "if ptrain.is_file() and pval.is_file():\n",
    "    voc2012.load_all_data()\n",
    "else:\n",
    "    voc2012.read_all_data_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count:  1464\n",
      "Val count:  1449\n",
      "Train image:  (224, 224, 3)\n",
      "Train label:  (224, 224)\n",
      "Unique classes:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train count: \", len(voc2012.train_images))\n",
    "print(\"Val count: \", len(voc2012.val_images))\n",
    "\n",
    "print(\"Train image: \", voc2012.train_images[0].shape)\n",
    "print(\"Train label: \", voc2012.train_labels[0].shape)\n",
    "\n",
    "print(\"Unique classes: \", np.unique(voc2012.train_labels))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(1,2)) # specifying the overall grid size\n",
    "\n",
    "\n",
    "plt.subplot(1,2,1)    # the number of images in the grid is 5*5 (25)\n",
    "plt.imshow(voc2012.train_images[0])\n",
    "\n",
    "plt.subplot(1,2,2)    # the number of images in the grid is 5*5 (25)\n",
    "plt.imshow(voc2012.train_labels[0], cmap='hot')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# f, axarr = plt.subplots(2,2)\n",
    "# axarr[0,0].imshow(voc2012.train_images[0])\n",
    "\n",
    "\n",
    "# axarr[0,1].imshow(voc2012.train_labels[0], cmap='hot')\n",
    "# # axarr[0,1].colorbar()\n",
    "# # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:1.7040\n"
     ]
    }
   ],
   "source": [
    "# Naive model training \n",
    "\n",
    "naive = Naive()\n",
    "criterion = getCrossEntropyLoss()\n",
    "train(naive, voc2012, criterion, num_epochs=1, batch_size=64, learning_rate=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "        \n",
    "    return (img_out / 255)\n",
    "\n",
    "color_dict = range(100, 1000, 25)\n",
    "color_dict = [*color_dict][:21]\n",
    "print(color_dict)\n",
    "\n",
    "plt.imshow(voc2012.train_images[1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(voc2012.train_labels[1], cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "img = np.expand_dims(voc2012.train_images[1], axis=0)\n",
    "# print(img.shape)\n",
    "\n",
    "pred = predict(naive, img)\n",
    "\n",
    "plt.imshow(labelVisualize(21, color_dict, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
